{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Поиск токсичных комментариев\n",
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.  \n",
    "Надо обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.   Метрика качества F1 не меньше 0.75.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек и компонентов\n",
    "import pandas as pd \n",
    "import nltk \n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv('toxic_comments.csv') \n",
    "stop_words = set(stopwords.words('english'))\n",
    "corpus = data['text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "0   Explanation\\nWhy the edits made under my usern...      0\n",
       "1   D'aww! He matches this background colour I'm s...      0\n",
       "2   Hey man, I'm really not trying to edit war. It...      0\n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4   You, sir, are my hero. Any chance you remember...      0\n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7   Your vandalism to the Matt Shirvington article...      0\n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9   alignment on this subject and which are contra...      0\n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0\n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0\n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "13  Before you start throwing accusations and warn...      0\n",
       "14  Oh, and the girl above started her arguments w...      0\n",
       "15  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...      0\n",
       "16  Bye! \\n\\nDon't look, come or think of comming ...      1\n",
       "17   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski      0\n",
       "18  The Mitsurugi point made no sense - why not ar...      0\n",
       "19  Don't mean to bother you \\n\\nI see that you're...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим данные\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции очистки и леммитизации текста\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "def lemmatize_text(text):\n",
    "    return lemmatizer.lemmatize(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание столбца с очищенным и леммитизированным текстом\n",
    "data['clean_text'] = data['text'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i cannot make any real suggestions on imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really do not think you understand i cam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                               clean_text  \n",
       "0       explanation why the edits made under my userna...  \n",
       "1       d aww he matches this background colour i am s...  \n",
       "2       hey man i am really not trying to edit war it ...  \n",
       "3       more i cannot make any real suggestions on imp...  \n",
       "4       you sir are my hero any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566  and for the second time of asking when your vi...  \n",
       "159567  you should be ashamed of yourself that is a ho...  \n",
       "159568  spitzer umm theres no actual article for prost...  \n",
       "159569  and it looks like it was actually you who put ...  \n",
       "159570  and i really do not think you understand i cam...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на тренировочную и тестовую выборки\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем три модели: Мешок слов, TF-IDF, CatBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование фичей и целевого признака train\n",
    "count_vect = CountVectorizer(stop_words=stop_words)  \n",
    "corpus_train = train['clean_text'].values.astype('U')\n",
    "X_train = count_vect.fit_transform(corpus_train) \n",
    "y_train = train['toxic'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Формирование фичей и целевого признака test\n",
    "corpus_test = test[['clean_text']].values.astype('U') \n",
    "X_test = count_vect.transform((corpus_test.ravel())) \n",
    "y_test = test['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на мешке слов: 0.7693888032871083\n"
     ]
    }
   ],
   "source": [
    "# Построение модели и вывод результата\n",
    "model = LogisticRegression(max_iter=1000) \n",
    "model.fit(X_train, y_train) \n",
    "pred = model.predict(X_test)\n",
    "f1_bow = f1_score(y_test, pred)\n",
    "print('F1 на мешке слов:', f1_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на TF-IDF: 0.7357997010463377\n"
     ]
    }
   ],
   "source": [
    "# Формирование фичей и целевого признака train\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords.words('english')) \n",
    "corpus_train = train['clean_text'].values.astype('U')\n",
    "X_train = count_tf_idf.fit_transform(corpus_train) \n",
    "y_train = train['toxic'].values \n",
    "\n",
    "# Формирование фичей и целевого признака test\n",
    "corpus_test = test['clean_text'].values.astype('U') \n",
    "X_test = count_tf_idf.transform(corpus_test) \n",
    "y_test = test['toxic'].values\n",
    "\n",
    "# Построение модели и вывод результата\n",
    "model = LogisticRegression(max_iter=1000) \n",
    "model.fit(X_train, y_train) \n",
    "pred = model.predict(X_test)\n",
    "f1_tf_idf = f1_score(y_test, pred)\n",
    "print('F1 на TF-IDF:', f1_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.104979\n",
      "0:\tlearn: 0.6525309\ttest: 0.6788504\tbest: 0.6788504 (0)\ttotal: 315ms\tremaining: 5m 14s\n",
      "100:\tlearn: 0.6882322\ttest: 0.6905845\tbest: 0.6908263 (99)\ttotal: 17.6s\tremaining: 2m 36s\n",
      "200:\tlearn: 0.7051434\ttest: 0.6955911\tbest: 0.6961094 (182)\ttotal: 34.5s\tremaining: 2m 16s\n",
      "300:\tlearn: 0.7157885\ttest: 0.7000176\tbest: 0.7018775 (290)\ttotal: 50.7s\tremaining: 1m 57s\n",
      "400:\tlearn: 0.7239167\ttest: 0.6998947\tbest: 0.7018775 (290)\ttotal: 1m 6s\tremaining: 1m 40s\n",
      "500:\tlearn: 0.7318767\ttest: 0.7028260\tbest: 0.7030729 (496)\ttotal: 1m 23s\tremaining: 1m 22s\n",
      "600:\tlearn: 0.7383846\ttest: 0.7020193\tbest: 0.7037752 (548)\ttotal: 1m 39s\tremaining: 1m 5s\n",
      "700:\tlearn: 0.7448524\ttest: 0.7013718\tbest: 0.7037752 (548)\ttotal: 1m 55s\tremaining: 49.2s\n",
      "800:\tlearn: 0.7502519\ttest: 0.7024648\tbest: 0.7037752 (548)\ttotal: 2m 11s\tremaining: 32.7s\n",
      "900:\tlearn: 0.7559269\ttest: 0.7027978\tbest: 0.7037752 (548)\ttotal: 2m 27s\tremaining: 16.2s\n",
      "999:\tlearn: 0.7599388\ttest: 0.7031963\tbest: 0.7037752 (548)\ttotal: 2m 43s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7037752414\n",
      "bestIteration = 548\n",
      "\n",
      "Shrink model to first 549 iterations.\n",
      "F1 на CatBoost: 0.7037752414398595\n"
     ]
    }
   ],
   "source": [
    "X_col = ['text']\n",
    "y_col = ['toxic']\n",
    "text_features = ['text']\n",
    "\n",
    "model = CatBoostClassifier(verbose=100,text_features=text_features, eval_metric = 'F1')\n",
    "model.fit(train[X_col], train[y_col], eval_set= (test[X_col],test[y_col]))\n",
    "pred = model.predict(test[X_col])\n",
    "f1_cb = f1_score(test[y_col], pred)\n",
    "print('F1 на CatBoost:', f1_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на мешке слов: 0.7693888032871083\n",
      "F1 на TF-IDF: 0.7357997010463377\n",
      "F1 на CatBoost: 0.7037752414398595\n"
     ]
    }
   ],
   "source": [
    "print('F1 на мешке слов:', f1_bow)\n",
    "print('F1 на TF-IDF:', f1_tf_idf)\n",
    "print('F1 на CatBoost:', f1_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшей моделью является \"Мешок слов\" с целевым значением F1= 0.77."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
